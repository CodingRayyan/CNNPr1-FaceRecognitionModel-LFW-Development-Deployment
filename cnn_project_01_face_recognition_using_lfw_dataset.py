# -*- coding: utf-8 -*-
"""CNN Project 01: Face Recognition using LFW DataSet

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UellvahMXeo21nDR5uFc5mNX8hb69r8C

<br>

# AI Domain: Convolutional Neural Network (CNN)
## CNN Project 01: Face Recognition using LFW DataSet.

| Prepared by | Rayyan Ahmed |
|-------------|--------------|
| Date | 20-21th March, 2025

<br>

### Libraries Used:
- Numpy
- Pandas
- Matplotlib
- Scikit-Learn
- Tensorflow
- Keras
- Streamlit (Model Deployment in other app.py)
- Pillow

<br>

# Loading dataFrame

<br>
"""

import numpy as np
from sklearn.datasets import fetch_lfw_people

df = fetch_lfw_people(min_faces_per_person = 70, resize = 0.4)
df

"""<br>

# DataSet SHape

<br>
"""

df.data.shape, df.images.shape, df.target.shape, df.target_names.shape

"""#### Each row in the data array corresponds to one image, and each value in that row represents a pixel's intensity (normalized between 0 and 1).
#### Since the shape is (1288, 1850):
- 1288 → Total number of images.
- 1850 → Number of pixel values per image (which means each image has 1850 pixels).
#### Example:
- Look at the first row of data: [0.9973857 , 0.99607843, 0.9921568 , ..., 0.38169935, 0.38823533, 0.3803922 ] which is representing 1st image of dataset.
- Here, the values "0.9973857, 0.99607843... 0.3803922" are representing the pixels of 1st image.
- i.e: 1st pixel is 99.73857% gray, 2nd is 99.607843% gray and last pixel is 38.03922% gray.

---

#### Each double bracket [[ ... ]] represents a single image, which is a 2D matrix (height × width).
#### From the shape (1288, 50, 37), we can see that:
- Each image has 50 rows (height).
- Each row has 37 values (width, i.e., columns).
- Each double bracket [[ ... ]] contains 50 rows, where each row has 37 values.

<br>

# Getting Image Pixels of Target Label 1:

<br>
"""

images_label_i = df.images[df.target == 1]
print(images_label_i)

"""<br>

# Plotting Images for Target Names

<br>
"""

import matplotlib.pyplot as plt

for label, name in enumerate(df.target_names):
    print(f"Label: {label}, Name: {name}")

ask = input("\nEnter label for name: ")
num = int(input("Enter number of images: "))

image_label = df.images[df.target == int(ask)]

for i in range(min(len(image_label), num)):
    print(f"\nShowing image {i+1} of {df.target_names[int(ask)]}")
    plt.imshow(image_label[i], cmap='gray')
    plt.axis('off')
    plt.show()

"""<br>

# Accessing Single Image

<br>
"""

name_index = {'Ariel Sharon' : 0, 'Colin Powell' : 1, 'Donald Rumsfeld' : 2, 'George W Bush' : 3,'Gerhard Schroeder' : 4, 'Hugo Chavez' : 5, 'Tony Blair' : 6}
name_index['Ariel Sharon']

image = df.data[4].reshape((50, 37))

plt.imshow(image, cmap='gray')
plt.axis('off')
plt.show()

"""<br>

# Seperating x & y axis

<br>
"""

x, y = df.images, df.target

target_names = df.target_names

print(f"x shape: {x.shape}, y shape: {y.shape}")

x.shape, y.shape

"""<br>

# Reshaping x for CNN Ease

<br>
"""

x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)

"""<br>

# One-hot Encoding of y

<br>
"""

from tensorflow.keras.utils import to_categorical

cat_y = to_categorical(y)
cat_y, cat_y[0], len(cat_y[0])

"""<br>

# Train Test Split

<br>
"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, cat_y, test_size = 0.2, random_state = 42)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

"""<br>

# Building Sequential Layers

<br>
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(50, 37, 1)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    #Dropout(0.5),
    Dense(len(target_names), activation='softmax')  # Output layer
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""<br>

# Fitting Model

<br>
"""

history = model.fit(x_train, y_train, epochs = 20, batch_size = 32, validation_data = (x_test, y_test))
history

history.history

"""<br>

# Model Accuracy

<br>
"""

test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_acc * 100:.3f} %")

"""<br>

# Classification Report

<br>
"""

from sklearn.metrics import classification_report
import numpy as np

y_pred = model.predict(x_test)

y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

report = classification_report(y_true_classes, y_pred_classes, target_names = target_names)
print(report)

model.predict(x_test)[0]

np.argmax(model.predict(x_test), axis = 1)[0]

"""<br>

# Image Name Predictor

<br>
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

def predict_face_from_dataset(index):
    img = x_test[index]

    img_expanded = np.expand_dims(img, axis=0)

    prediction = model.predict(img_expanded)
    predicted_class = np.argmax(prediction)
    predicted_name = target_names[predicted_class]

    plt.imshow(img.squeeze(), cmap="gray")
    plt.title(f"Predicted: {predicted_name}")
    plt.axis("off")
    plt.show()

predict_face_from_dataset(7)

"""<br>

# Model Saving

<br>
"""

saved_model = model.save("lfw_prone.keras")

"""<br>

# Downloading Saved Model

<br>
"""

from google.colab import files
files.download("lfw_prone.keras")